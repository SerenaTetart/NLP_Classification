{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36a13b9",
   "metadata": {},
   "source": [
    "<h2> NLP Classification - Fake news detection system </h2>\n",
    "\n",
    "In this notebook we'll study how to make a Fake news detection system based on NLP classification using different methods such as Naive Baye, LSTM and transformers (Bert in particular).\n",
    "\n",
    "<h3> Introduction - Quick Data exploration </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045a735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>China is in the South China Sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>President-Elect</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c2723a188</td>\n",
       "      <td>0</td>\n",
       "      <td>With the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>U.S. senator</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6936b216e5d</td>\n",
       "      <td>0</td>\n",
       "      <td>The (Wisconsin) governor has proposed tax give...</td>\n",
       "      <td>corporations,pundits,taxes,abc-news-week</td>\n",
       "      <td>donna-brazile</td>\n",
       "      <td>Political commentator</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5cd9195738</td>\n",
       "      <td>1</td>\n",
       "      <td>Says her representation of an ex-boyfriend who...</td>\n",
       "      <td>candidates-biography,children,ethics,families,...</td>\n",
       "      <td>rebecca-bradley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84f8dac7737</td>\n",
       "      <td>0</td>\n",
       "      <td>At protests in Wisconsin against proposed coll...</td>\n",
       "      <td>health-care,labor,state-budget</td>\n",
       "      <td>republican-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label                                          statement  \\\n",
       "0  81f884c64a7      1  China is in the South China Sea and (building)...   \n",
       "1  30c2723a188      0  With the resources it takes to execute just ov...   \n",
       "2  6936b216e5d      0  The (Wisconsin) governor has proposed tax give...   \n",
       "3  b5cd9195738      1  Says her representation of an ex-boyfriend who...   \n",
       "4  84f8dac7737      0  At protests in Wisconsin against proposed coll...   \n",
       "\n",
       "                                             subject  \\\n",
       "0                      china,foreign-policy,military   \n",
       "1                                        health-care   \n",
       "2           corporations,pundits,taxes,abc-news-week   \n",
       "3  candidates-biography,children,ethics,families,...   \n",
       "4                     health-care,labor,state-budget   \n",
       "\n",
       "                      speaker            speaker_job        state_info  \\\n",
       "0                donald-trump        President-Elect          New York   \n",
       "1                  chris-dodd           U.S. senator       Connecticut   \n",
       "2               donna-brazile  Political commentator  Washington, D.C.   \n",
       "3             rebecca-bradley                    NaN               NaN   \n",
       "4  republican-party-wisconsin                    NaN         Wisconsin   \n",
       "\n",
       "  party_affiliation  \n",
       "0        republican  \n",
       "1          democrat  \n",
       "2          democrat  \n",
       "3              none  \n",
       "4        republican  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(os.path.join(\"fakeNews.csv\"), encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f74a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values:\n",
      "id                      0\n",
      "label                   0\n",
      "statement               0\n",
      "subject                 0\n",
      "speaker                 0\n",
      "speaker_job          2481\n",
      "state_info           1929\n",
      "party_affiliation       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of NaN values:\\n' + str(data.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a881c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5795\n",
      "0    3155\n",
      "Name: label, dtype: int64\n",
      "1    0.647486\n",
      "0    0.352514\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data['label'].value_counts(normalize=False))\n",
    "print(data['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1498e4d",
   "metadata": {},
   "source": [
    "<h3> Part I - Naive Baye Classification: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c571c369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 7607\n",
      "test len: 1343\n",
      "Accuracy: 0.6291883842144452\n",
      "F1 score: 0.7257709251101322\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def NB_text_processing(text):\n",
    "    ''' Return cleaned text for Machine Learning '''\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    NEW_LINE = re.compile('\\n')\n",
    "    BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "    STEMMER = SnowballStemmer('english')\n",
    "\n",
    "    text = text.lower()\n",
    "    text = unidecode.unidecode(text)\n",
    "    text = NEW_LINE.sub(' ',text)\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ',text)\n",
    "    text = BAD_SYMBOLS_RE.sub('',text)\n",
    "    text = ' '.join([STEMMER.stem(word) for word in text.split() if word not in STOPWORDS])\n",
    "    return text\n",
    "\n",
    "def NB_preprocessing(data):\n",
    "    ''' Return train, validation and test set '''\n",
    "    X = data['statement'].tolist()\n",
    "    X = [NB_text_processing(txt) for txt in X]\n",
    "    cv = CountVectorizer(max_features = 5000)\n",
    "\n",
    "    X = cv.fit_transform(X).toarray()\n",
    "    Y = data['label'].tolist()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.15,train_size=0.85)\n",
    "    print('train len:', len(x_train))\n",
    "    print('test len:', len(x_test))\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def NB_Model(data):\n",
    "    ''' Create a model based on Naive Bayes '''\n",
    "    x_train, x_test, y_train, y_test = NB_preprocessing(data)\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('F1 score:', f1_score(y_test, y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cm, classes=['True', 'Fake'])\n",
    "\n",
    "NB_Model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c39038",
   "metadata": {},
   "source": [
    "The accuracy is 62.92% which is pretty good knowing that we are using Naive Baye, sometimes the simplest solutions are the best, but we need to improve this result.\n",
    "\n",
    "But we can notice that the model is more confident in classifying fake news than true information.\n",
    "\n",
    "<h3> Part II - LSTM Classification: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea7e329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       china south china sea build militari fortress ...\n",
      "1       resourc take execut three month iraq war could...\n",
      "2           wisconsin governor propos tax giveaway corpor\n",
      "3       say represent exboyfriend friend famili law ca...\n",
      "4       protest wisconsin propos collect bargain chang...\n",
      "                              ...                        \n",
      "8945    rhode island hybrid retir plan well first stat...\n",
      "8946    new health care law forc senior barack obama g...\n",
      "8947    health insur plan member congress differ feder...\n",
      "8948    one american histori move june 16 announc may ...\n",
      "8949         say armi spend 7 million sponsor nascar team\n",
      "Name: statement, Length: 8950, dtype: object\n",
      "Maximum length of a sentence is :  227\n",
      "Vocabulary Size : 8636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "\n",
    "X = data['statement'].apply(lambda x: NB_text_processing(x))\n",
    "Y = data['label'].tolist()\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y)\n",
    "Y.reshape(-1, 1)\n",
    "print(X)\n",
    "\n",
    "c=[]\n",
    "for i in range(len(X)):\n",
    "    m=len(X[i].split())\n",
    "    c.append(m)\n",
    "print('Maximum length of a sentence is : ',max(c))\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size :\", vocab_size)\n",
    "\n",
    "X = pad_sequences(tokenizer.texts_to_sequences(X), maxlen = max(c))\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.15,train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a8f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "''' You have to download this file: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "    his weight is 1GO !'''\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open('glove.6B.300d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = value = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' %len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "embedding_layer = Embedding(vocab_size\n",
    "    , EMBEDDING_DIM\n",
    "    , weights=[embedding_matrix]\n",
    "    , input_length=max(c)\n",
    "    , trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1df599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 227)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 227, 300)          2590800   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 227, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 223, 64)           96064     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,082,129\n",
      "Trainable params: 491,329\n",
      "Non-trainable params: 2,590,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def MakeModel():\n",
    "    sequence_input = Input(shape=(max(c),), dtype='int32')\n",
    "    embedding_sequences = embedding_layer(sequence_input)\n",
    "    x = SpatialDropout1D(0.2)(embedding_sequences)\n",
    "    x = Conv1D(64, 5, activation='relu')(x)\n",
    "    x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(sequence_input, outputs)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = MakeModel()\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1, min_lr = 0.01, monitor = 'val_loss', verbose = 1)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3bb505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "15/15 [==============================] - 87s 5s/step - loss: 0.6553 - accuracy: 0.6309 - val_loss: 0.6288 - val_accuracy: 0.6724\n",
      "Epoch 2/4\n",
      "15/15 [==============================] - 76s 5s/step - loss: 0.6359 - accuracy: 0.6426 - val_loss: 0.6267 - val_accuracy: 0.6828\n",
      "Epoch 3/4\n",
      "15/15 [==============================] - 81s 5s/step - loss: 0.6238 - accuracy: 0.6535 - val_loss: 0.6200 - val_accuracy: 0.6813\n",
      "Epoch 4/4\n",
      "15/15 [==============================] - 76s 5s/step - loss: 0.6069 - accuracy: 0.6693 - val_loss: 0.6200 - val_accuracy: 0.6716\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=4, validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625ef34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6716306775874907\n",
      "F1 score: 0.7876745305729417\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "y_tmp = model.predict(x_test)\n",
    "y_pred = []\n",
    "for i in range(len(y_tmp)):\n",
    "    if(y_tmp[i] > threshold): y_pred.append(1)\n",
    "    else: y_pred.append(0)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm, classes=['True', 'Fake'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93edb67",
   "metadata": {},
   "source": [
    "Sadly the LSTM model tend to predict a lot of Fake news.\n",
    "\n",
    "Though the accuracy is a bit better than Naive Baye with 67.16%\n",
    "\n",
    "<h3> Part III - Bert Classification: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ef9190",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "300/7226. Average loss: 0.6639546110232671 | Accuracy: 63.0%\n",
      "600/7226. Average loss: 0.6519798828164737 | Accuracy: 64.5%\n",
      "900/7226. Average loss: 0.6680497904618581 | Accuracy: 63.888888888888886%\n",
      "1200/7226. Average loss: 0.6817441352208455 | Accuracy: 62.25000000000001%\n",
      "1500/7226. Average loss: 0.6544746200243632 | Accuracy: 62.46666666666667%\n",
      "1800/7226. Average loss: 0.6578336762388547 | Accuracy: 62.83333333333333%\n",
      "2100/7226. Average loss: 0.6540734585126241 | Accuracy: 62.95238095238095%\n",
      "2400/7226. Average loss: 0.6374216807385286 | Accuracy: 63.33333333333333%\n",
      "2700/7226. Average loss: 0.6617439130942027 | Accuracy: 63.33333333333333%\n",
      "3000/7226. Average loss: 0.6675263519088427 | Accuracy: 63.26666666666667%\n",
      "3300/7226. Average loss: 0.6334609126051267 | Accuracy: 63.66666666666667%\n",
      "3600/7226. Average loss: 0.6613467560211818 | Accuracy: 63.55555555555556%\n",
      "3900/7226. Average loss: 0.6705454394221306 | Accuracy: 63.43589743589744%\n",
      "4200/7226. Average loss: 0.6062782700856527 | Accuracy: 63.95238095238095%\n",
      "4500/7226. Average loss: 0.6735467990239461 | Accuracy: 63.866666666666674%\n",
      "4800/7226. Average loss: 0.6400369946161906 | Accuracy: 64.04166666666666%\n",
      "5100/7226. Average loss: 0.6421798198421796 | Accuracy: 64.13725490196079%\n",
      "5400/7226. Average loss: 0.6521789474288623 | Accuracy: 64.11111111111111%\n",
      "5700/7226. Average loss: 0.6600706784923871 | Accuracy: 63.96491228070176%\n",
      "6000/7226. Average loss: 0.6384541088342667 | Accuracy: 64.1%\n",
      "6300/7226. Average loss: 0.6583281375964483 | Accuracy: 64.04761904761904%\n",
      "6600/7226. Average loss: 0.6566621358195941 | Accuracy: 64.01515151515152%\n",
      "6900/7226. Average loss: 0.6496568693717321 | Accuracy: 64.05797101449275%\n",
      "7200/7226. Average loss: 0.5934999816616376 | Accuracy: 64.38888888888889%\n",
      "Average val loss: 0.6440734818204069 | Val accuracy: 65.20376175548589%\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "300/7226. Average loss: 0.6371077605088552 | Accuracy: 66.33333333333333%\n",
      "600/7226. Average loss: 0.6429421983162562 | Accuracy: 66.16666666666666%\n",
      "900/7226. Average loss: 0.6633902614315351 | Accuracy: 65.11111111111111%\n",
      "1200/7226. Average loss: 0.6785810055335363 | Accuracy: 63.083333333333336%\n",
      "1500/7226. Average loss: 0.6497334709763527 | Accuracy: 63.46666666666667%\n",
      "1800/7226. Average loss: 0.6469369552532832 | Accuracy: 63.72222222222222%\n",
      "2100/7226. Average loss: 0.6505006945133209 | Accuracy: 63.761904761904766%\n",
      "2400/7226. Average loss: 0.6366668884456158 | Accuracy: 64.04166666666666%\n",
      "2700/7226. Average loss: 0.660320621728897 | Accuracy: 63.92592592592593%\n",
      "3000/7226. Average loss: 0.6626382571458816 | Accuracy: 63.800000000000004%\n",
      "3300/7226. Average loss: 0.6297682886322339 | Accuracy: 64.15151515151514%\n",
      "3600/7226. Average loss: 0.6608498233556748 | Accuracy: 64.0%\n",
      "3900/7226. Average loss: 0.6681086192528407 | Accuracy: 63.82051282051282%\n",
      "4200/7226. Average loss: 0.603617475827535 | Accuracy: 64.30952380952381%\n",
      "4500/7226. Average loss: 0.6653753820061684 | Accuracy: 64.2%\n",
      "4800/7226. Average loss: 0.6356072656313578 | Accuracy: 64.35416666666667%\n",
      "5100/7226. Average loss: 0.6365591799716155 | Accuracy: 64.4313725490196%\n",
      "5400/7226. Average loss: 0.6479184840122859 | Accuracy: 64.42592592592592%\n",
      "5700/7226. Average loss: 0.6542435764273008 | Accuracy: 64.33333333333333%\n",
      "6000/7226. Average loss: 0.6363619541128477 | Accuracy: 64.43333333333334%\n",
      "6300/7226. Average loss: 0.6610800308982531 | Accuracy: 64.36507936507937%\n",
      "6600/7226. Average loss: 0.6585056249300639 | Accuracy: 64.30303030303031%\n",
      "6900/7226. Average loss: 0.6424533009529114 | Accuracy: 64.34782608695652%\n",
      "7200/7226. Average loss: 0.5908508801956972 | Accuracy: 64.66666666666666%\n",
      "Average val loss: 0.6413935937197605 | Val accuracy: 65.20376175548589%\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "300/7226. Average loss: 0.6384679340322812 | Accuracy: 66.0%\n",
      "600/7226. Average loss: 0.6428432855010032 | Accuracy: 66.0%\n",
      "900/7226. Average loss: 0.6603970369696617 | Accuracy: 64.88888888888889%\n",
      "1200/7226. Average loss: 0.6684774323304494 | Accuracy: 63.16666666666667%\n",
      "1500/7226. Average loss: 0.6342560217281182 | Accuracy: 63.33333333333333%\n",
      "1800/7226. Average loss: 0.6474359561999639 | Accuracy: 63.55555555555556%\n",
      "2100/7226. Average loss: 0.6495296969016393 | Accuracy: 63.523809523809526%\n",
      "2400/7226. Average loss: 0.632157928943634 | Accuracy: 63.83333333333333%\n",
      "2700/7226. Average loss: 0.6606392826636632 | Accuracy: 63.70370370370371%\n",
      "3000/7226. Average loss: 0.6663760992884636 | Accuracy: 63.6%\n",
      "3300/7226. Average loss: 0.6236097384492556 | Accuracy: 63.96969696969697%\n",
      "3600/7226. Average loss: 0.6597624911864599 | Accuracy: 63.83333333333333%\n",
      "3900/7226. Average loss: 0.6631463167071342 | Accuracy: 63.64102564102564%\n",
      "4200/7226. Average loss: 0.598405960003535 | Accuracy: 64.14285714285714%\n",
      "4500/7226. Average loss: 0.6638313184181849 | Accuracy: 64.02222222222223%\n",
      "4800/7226. Average loss: 0.6373621392250061 | Accuracy: 64.1875%\n",
      "5100/7226. Average loss: 0.6396291068693002 | Accuracy: 64.25490196078431%\n",
      "5400/7226. Average loss: 0.6456501869360606 | Accuracy: 64.22222222222223%\n",
      "5700/7226. Average loss: 0.6530187850197157 | Accuracy: 64.0701754385965%\n",
      "6000/7226. Average loss: 0.634336635172367 | Accuracy: 64.18333333333334%\n",
      "6300/7226. Average loss: 0.6596338504056136 | Accuracy: 64.12698412698413%\n",
      "6600/7226. Average loss: 0.6516107328732809 | Accuracy: 64.12121212121212%\n",
      "6900/7226. Average loss: 0.644743584394455 | Accuracy: 64.17391304347827%\n",
      "7200/7226. Average loss: 0.5863103329141934 | Accuracy: 64.5%\n",
      "Average val loss: 0.6388777213106895 | Val accuracy: 65.20376175548589%\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def Bert_preprocess_text(text, device, tokenizer):\n",
    "    ''' Split text in chunks of 'delta' words strictly then encode it'''\n",
    "    parts = []\n",
    "    text_len = len(text.split(' '))\n",
    "    delta = 200\n",
    "    max_parts = 5\n",
    "    nb_cuts = int(text_len / delta)\n",
    "    nb_cuts = min(nb_cuts, max_parts)\n",
    "    \n",
    "    for i in range(nb_cuts + 1):\n",
    "        text_part = ' '.join(text.split(' ')[i * delta: (i + 1) * delta])\n",
    "        parts.append(tokenizer.encode(text_part, return_tensors=\"pt\", max_length=500).to(device))\n",
    "\n",
    "    return parts\n",
    "\n",
    "def Bert_train_epoch(model, x_train, y_train, loss_fn, optimizer, device, tokenizer):\n",
    "    ''' Train Bert model for one epoch '''\n",
    "    print_every = 300; total_loss = 0\n",
    "    all_losses = []\n",
    "    model.train()\n",
    "    correct_predictions = 0\n",
    "    for idx in range(len(x_train)):\n",
    "        text_parts = Bert_preprocess_text(x_train[idx], device, tokenizer)\n",
    "        label = torch.tensor([y_train[idx]]).long().to(device)\n",
    "        overall_output = torch.zeros(2).float().to(device)\n",
    "        for part in text_parts:\n",
    "            if len(part) > 0:\n",
    "                try:\n",
    "                    input = part.reshape(-1)[:512].reshape(1, -1)\n",
    "                    overall_output += (model(input, labels=label)[1].float().to(device))[0]\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "        correct_predictions += (np.argmax(overall_output.cpu().detach().numpy()) == label).item()\n",
    "        if label == 0: label = torch.tensor([1.0, 0.0]).float().to(device)\n",
    "        elif label == 1: label = torch.tensor([0.0, 1.0]).float().to(device)\n",
    "        loss = loss_fn(overall_output, label)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if idx % print_every == 0 and idx > 0:\n",
    "            average_loss = total_loss / print_every\n",
    "            print(\"{}/{}. Average loss: {} | Accuracy: {}%\".format(idx, len(x_train), average_loss, (correct_predictions/idx)*100))\n",
    "            all_losses.append(average_loss)\n",
    "            total_loss = 0\n",
    "            \n",
    "def Bert_eval_model(model, x_val, y_val, loss_fn, device, tokenizer):\n",
    "    ''' Evaluate Bert model on validation data '''\n",
    "    total_loss = 0; all_losses = []\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(x_val)):\n",
    "            text_parts = Bert_preprocess_text(x_val[idx], device, tokenizer)\n",
    "            label = torch.tensor([y_val[idx]]).long().to(device)\n",
    "            overall_output = torch.zeros(2).float().to(device)\n",
    "            for part in text_parts:\n",
    "                if len(part) > 0:\n",
    "                    try:\n",
    "                        input = part.reshape(-1)[:512].reshape(1, -1)\n",
    "                        overall_output += (model(input, labels=label)[1].float().to(device))[0]\n",
    "                    except Exception as e:\n",
    "                        print(str(e))\n",
    "            correct_predictions += (np.argmax(overall_output.cpu().detach().numpy()) == label).item()\n",
    "            if label == 0: label = torch.tensor([1.0, 0.0]).float().to(device)\n",
    "            elif label == 1: label = torch.tensor([0.0, 1.0]).float().to(device)\n",
    "            loss = loss_fn(overall_output, label)\n",
    "            total_loss += loss.item()\n",
    "        average_loss = total_loss / len(x_val)\n",
    "        print(\"Average val loss: {} | Val accuracy: {}%\".format(average_loss, (correct_predictions/len(x_val))*100))\n",
    "        all_losses.append(average_loss)\n",
    "        total_loss = 0\n",
    "    \n",
    "\n",
    "def Bert_train_model(X, Y):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    x, x_test, y, y_test = train_test_split(X,Y,test_size=0.05,train_size=0.95)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,y,test_size=0.15,train_size=0.85)\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "    model.config.num_labels = 1\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False #Freeze Bert !\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(model.config.hidden_size, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 2),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = optim.AdamW(model.classifier.parameters(), lr=3e-5)\n",
    "    \n",
    "    EPOCHS = 3\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f'\\nEpoch {epoch + 1}/{EPOCHS}')\n",
    "        print('-' * 10)\n",
    "        Bert_train_epoch(model, x_train, y_train, criterion, optimizer, device, tokenizer)\n",
    "        Bert_eval_model(model, x_val, y_val, criterion, device, tokenizer)\n",
    "        \n",
    "X = data['statement'].tolist()\n",
    "Y = data['label'].tolist()\n",
    "Bert_train_model(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf81e5c",
   "metadata": {},
   "source": [
    "As we can see the model is learning nothing from Fake news because the problem with fake news is that you can't classify it based only on text, you also need context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba35975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
